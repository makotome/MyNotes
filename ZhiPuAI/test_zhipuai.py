"""
æ™ºè°±AIæ¨¡å‹æµ‹è¯•è„šæœ¬
æµ‹è¯•æ™ºè°±AIçš„å„ç§æ¨¡å‹åŠŸèƒ½
"""

import os
import json
from zhipuai import ZhipuAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class ZhipuAITester:
    def __init__(self):
        """åˆå§‹åŒ–æ™ºè°±AIå®¢æˆ·ç«¯"""
        self.api_key = os.getenv('ZHIPUAI_API_KEY')
        if not self.api_key:
            raise ValueError("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®ZHIPUAI_API_KEY")
        
        self.client = ZhipuAI(api_key=self.api_key)
        
    def test_chat_completion(self, model="glm-4", messages=None):
        """
        æµ‹è¯•èŠå¤©è¡¥å…¨åŠŸèƒ½
        
        Args:
            model (str): æ¨¡å‹åç§°ï¼Œå¦‚ "glm-4", "glm-4v", "glm-3-turbo" ç­‰
            messages (list): æ¶ˆæ¯åˆ—è¡¨
        """
        if messages is None:
            messages = [
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
            ]
        
        print(f"ğŸš€ æµ‹è¯•æ¨¡å‹: {model}")
        print(f"ğŸ“ è¾“å…¥æ¶ˆæ¯: {json.dumps(messages, ensure_ascii=False, indent=2)}")
        
        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0.7,
                max_tokens=1000,
                stream=False
            )
            
            print("âœ… è¯·æ±‚æˆåŠŸï¼")
            print(f"ğŸ“„ å“åº”å†…å®¹: {response.choices[0].message.content}")
            print(f"ğŸ“Š ä½¿ç”¨token: {response.usage}")
            print("-" * 50)
            
            return response
            
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {str(e)}")
            return None
    
    def test_stream_chat(self, model="glm-4", messages=None):
        """
        æµ‹è¯•æµå¼èŠå¤©åŠŸèƒ½
        
        Args:
            model (str): æ¨¡å‹åç§°
            messages (list): æ¶ˆæ¯åˆ—è¡¨
        """
        if messages is None:
            messages = [
                {"role": "user", "content": "è¯·å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—"}
            ]
        
        print(f"ğŸŒŠ æµ‹è¯•æµå¼æ¨¡å‹: {model}")
        print(f"ğŸ“ è¾“å…¥æ¶ˆæ¯: {json.dumps(messages, ensure_ascii=False, indent=2)}")
        
        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0.7,
                max_tokens=1000,
                stream=True
            )
            
            print("âœ… æµå¼è¯·æ±‚å¼€å§‹ï¼")
            print("ğŸ“„ å“åº”å†…å®¹: ", end="")
            
            full_content = ""
            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    content = chunk.choices[0].delta.content
                    print(content, end="", flush=True)
                    full_content += content
            
            print("\nâœ… æµå¼å“åº”å®Œæˆï¼")
            print("-" * 50)
            
            return full_content
            
        except Exception as e:
            print(f"âŒ æµå¼è¯·æ±‚å¤±è´¥: {str(e)}")
            return None
    
    def test_function_calling(self, model="glm-4"):
        """
        æµ‹è¯•å‡½æ•°è°ƒç”¨åŠŸèƒ½
        """
        # å®šä¹‰å‡½æ•°
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "get_weather",
                    "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "city": {
                                "type": "string",
                                "description": "åŸå¸‚åç§°"
                            }
                        },
                        "required": ["city"]
                    }
                }
            }
        ]
        
        messages = [
            {"role": "user", "content": "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}
        ]
        
        print(f"ğŸ”§ æµ‹è¯•å‡½æ•°è°ƒç”¨åŠŸèƒ½: {model}")
        print(f"ğŸ“ è¾“å…¥æ¶ˆæ¯: {json.dumps(messages, ensure_ascii=False, indent=2)}")
        
        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                tools=tools,
                tool_choice="auto"
            )
            
            print("âœ… å‡½æ•°è°ƒç”¨è¯·æ±‚æˆåŠŸï¼")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if response.choices[0].message.tool_calls:
                for tool_call in response.choices[0].message.tool_calls:
                    print(f"ğŸ”§ è°ƒç”¨å‡½æ•°: {tool_call.function.name}")
                    print(f"ğŸ“‹ å‡½æ•°å‚æ•°: {tool_call.function.arguments}")
            else:
                print(f"ğŸ“„ æ™®é€šå“åº”: {response.choices[0].message.content}")
            
            print("-" * 50)
            return response
            
        except Exception as e:
            print(f"âŒ å‡½æ•°è°ƒç”¨å¤±è´¥: {str(e)}")
            return None
    
    def test_vision_model(self, model="glm-4v"):
        """
        æµ‹è¯•è§†è§‰æ¨¡å‹åŠŸèƒ½ï¼ˆéœ€è¦å›¾ç‰‡URLï¼‰
        """
        # ä½¿ç”¨ä¸€ä¸ªç¤ºä¾‹å›¾ç‰‡URL
        image_url = "https://img1.baidu.com/it/u=1369931113,3388870256&fm=253&app=138&size=w931&n=0&f=JPEG&fmt=auto"
        
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "è¯·æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹"},
                    {"type": "image_url", "image_url": {"url": image_url}}
                ]
            }
        ]
        
        print(f"ğŸ‘ï¸ æµ‹è¯•è§†è§‰æ¨¡å‹: {model}")
        print(f"ğŸ–¼ï¸ å›¾ç‰‡URL: {image_url}")
        
        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0.7,
                max_tokens=1000
            )
            
            print("âœ… è§†è§‰æ¨¡å‹è¯·æ±‚æˆåŠŸï¼")
            print(f"ğŸ“„ å›¾ç‰‡æè¿°: {response.choices[0].message.content}")
            print("-" * 50)
            
            return response
            
        except Exception as e:
            print(f"âŒ è§†è§‰æ¨¡å‹è¯·æ±‚å¤±è´¥: {str(e)}")
            return None
    
    def run_comprehensive_test(self):
        """è¿è¡Œå…¨é¢æµ‹è¯•"""
        print("ğŸ¯ å¼€å§‹æ™ºè°±AIå…¨é¢æµ‹è¯•...")
        print("=" * 60)
        
        # 1. åŸºç¡€èŠå¤©æµ‹è¯•
        print("1ï¸âƒ£ åŸºç¡€èŠå¤©æµ‹è¯•")
        self.test_chat_completion("glm-4")
        
        # 2. æµå¼èŠå¤©æµ‹è¯•
        print("2ï¸âƒ£ æµå¼èŠå¤©æµ‹è¯•")
        self.test_stream_chat("glm-4")
        
        # 3. ä¸åŒæ¨¡å‹æµ‹è¯•
        print("3ï¸âƒ£ æµ‹è¯•ä¸åŒæ¨¡å‹")
        models_to_test = ["glm-4", "glm-3-turbo"]
        for model in models_to_test:
            messages = [{"role": "user", "content": f"è¯·ç”¨ä¸€å¥è¯ä»‹ç»{model}æ¨¡å‹"}]
            self.test_chat_completion(model, messages)
        
        # 4. å‡½æ•°è°ƒç”¨æµ‹è¯•
        print("4ï¸âƒ£ å‡½æ•°è°ƒç”¨æµ‹è¯•")
        self.test_function_calling("glm-4")
        
        # 5. è§†è§‰æ¨¡å‹æµ‹è¯•ï¼ˆå¦‚æœæ”¯æŒï¼‰
        print("5ï¸âƒ£ è§†è§‰æ¨¡å‹æµ‹è¯•")
        self.test_vision_model("glm-4v")
        
        print("ğŸ‰ å…¨é¢æµ‹è¯•å®Œæˆï¼")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºæµ‹è¯•å®ä¾‹
        tester = ZhipuAITester()
        
        # è¿è¡Œå…¨é¢æµ‹è¯•
        tester.run_comprehensive_test()
        
        # æˆ–è€…å•ç‹¬æµ‹è¯•æŸä¸ªåŠŸèƒ½
        # tester.test_chat_completion("glm-4", [{"role": "user", "content": "Hello!"}])
        # tester.test_stream_chat("glm-4")
        # tester.test_function_calling("glm-4")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")

if __name__ == "__main__":
    main()
