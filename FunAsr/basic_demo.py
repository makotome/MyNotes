"""
SenseVoiceSmall åŸºç¡€ä½¿ç”¨ç¤ºä¾‹
æ”¯æŒæœ¬åœ°æ¨¡å‹è·¯å¾„
"""

try:
    from funasr import AutoModel  # type: ignore
    from funasr.utils.postprocess_utils import rich_transcription_postprocess  # type: ignore
except ImportError as e:
    print("âŒ æœªæ£€æµ‹åˆ° funasr åº“ï¼Œè¯·å…ˆå®‰è£…ï¼špip install funasr")
    raise e

import os

class SenseVoiceDemo:
    def __init__(self, model_path=None, device="auto"):
        # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•ï¼Œä¿è¯ base_dir å¯ç”¨
        base_dir = os.path.dirname(os.path.abspath(__file__))
        """
        åˆå§‹åŒ– SenseVoiceSmall æ¨¡å‹
        
        Args:
            model_path (str): æœ¬åœ°æ¨¡å‹è·¯å¾„æˆ– ModelScope æ¨¡å‹ID
            device (str): è¿è¡Œè®¾å¤‡ "cuda:0", "cpu", "auto"
        """
        # é»˜è®¤æ¨¡å‹è·¯å¾„ï¼Œè¯·æ ¹æ®æ‚¨çš„å®é™…è·¯å¾„ä¿®æ”¹
        if model_path is None:
            # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•ï¼Œæ–¹ä¾¿æœç´¢çˆ¶ç›®å½•ä¸‹çš„ models æ–‡ä»¶å¤¹
            base_dir = os.path.dirname(os.path.abspath(__file__))
            # å°è¯•æœ¬åœ°æ¨¡å‹è·¯å¾„æˆ–åœ¨çº¿æ¨¡å‹ID
            possible_paths = [
                os.path.join(base_dir, "models/SenseVoiceSmall"),      # å½“å‰ç›®å½•ä¸‹ models
                "iic/SenseVoiceSmall",                                 # åœ¨çº¿æ¨¡å‹ID
            ]
            
            # æ£€æŸ¥æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆæ’é™¤åœ¨çº¿æ¨¡å‹IDï¼‰
            for path in possible_paths[:-1]:
                expanded_path = os.path.expanduser(path)
                if os.path.exists(expanded_path):
                    model_path = expanded_path
                    break
            
            if model_path is None:
                # æœ¬åœ°æœªæ£€æµ‹åˆ°æ¨¡å‹ï¼Œä½¿ç”¨åœ¨çº¿æ¨¡å‹ID
                model_path = possible_paths[-1]
                print(f"âš ï¸  æœªåœ¨ {possible_paths[:-1]} ä¸­æ‰¾åˆ°æœ¬åœ°æ¨¡å‹ï¼Œä½¿ç”¨åœ¨çº¿æ¨¡å‹ {model_path}")
        
        self.model_path = model_path
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
        # æ£€æµ‹æœ¬åœ° VAD æ¨¡å‹è·¯å¾„
        vad_model_name = "fsmn-vad"
        local_vad_path = os.path.join(base_dir, "models/speech_fsmn_vad_zh-cn-16k-common-pytorch")
        if os.path.exists(local_vad_path):
            vad_model_name = local_vad_path
            print(f"âœ… æ£€æµ‹åˆ°æœ¬åœ° VAD æ¨¡å‹: {vad_model_name}")
        else:
            print(f"âš ï¸ æœªæ£€æµ‹åˆ°æœ¬åœ° VAD æ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤ VAD æ¨¡å‹: {vad_model_name}")
        
        # æ£€æµ‹æ˜¯å¦ä¸ºåœ¨çº¿æ¨¡å‹ID
        is_online = isinstance(model_path, str) and not os.path.isabs(model_path) and not os.path.exists(model_path)
        print(f"ğŸ” æ¨¡å‹ç±»å‹: {'åœ¨çº¿æ¨¡å‹' if is_online else 'æœ¬åœ°æ¨¡å‹'}")
        init_kwargs = {
            "model": model_path,
            "trust_remote_code": is_online,
            "vad_model": vad_model_name,
            "vad_kwargs": {"max_single_segment_time": 30000},
            "device": device,
        }
        if is_online:
            # åœ¨çº¿æ¨¡å‹ï¼Œä½¿ç”¨è¿œç¨‹ä»£ç 
            init_kwargs["remote_code"] = model_path
        # åˆå§‹åŒ–æ¨¡å‹
        try:
            self.model = AutoModel(**init_kwargs)
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            print("ğŸ’¡ è¯·æ£€æŸ¥ï¼š")
            print("   1. æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®")
            print("   2. æ˜¯å¦å®‰è£…äº†æ‰€éœ€ä¾èµ– (pip install -r requirements.txt)")
            print("   3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸ï¼ˆä½¿ç”¨åœ¨çº¿æ¨¡å‹æ—¶ï¼‰")
            raise e
    
    def transcribe_file(self, audio_path, language="auto", use_itn=True):
        """
        è½¬å½•éŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_path (str): éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language (str): è¯­è¨€ä»£ç  "auto", "zh", "en", "yue", "ja", "ko"
            use_itn (bool): æ˜¯å¦ä½¿ç”¨é€†æ–‡æœ¬æ ‡å‡†åŒ–ï¼ˆæ•°å­—ã€æ—¥æœŸç­‰è½¬æ¢ï¼‰
        
        Returns:
            dict: è¯†åˆ«ç»“æœï¼ŒåŒ…å«æ–‡æœ¬ã€æƒ…æ„Ÿã€äº‹ä»¶ç­‰ä¿¡æ¯
        """
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        
        print(f"ğŸµ æ­£åœ¨è¯†åˆ«éŸ³é¢‘: {audio_path}")
        print(f"ğŸŒ è¯­è¨€è®¾ç½®: {language}")
        
        try:
            # æ‰§è¡Œè¯†åˆ«
            result = self.model.generate(
                input=audio_path,
                cache={},
                language=language,
                use_itn=use_itn,
                batch_size_s=60,  # æ‰¹å¤„ç†å¤§å°
                merge_vad=True,   # åˆå¹¶VADç»“æœ
                merge_length_s=15,  # åˆå¹¶é•¿åº¦
            )
            
            # åå¤„ç†æ–‡æœ¬
            if result and len(result) > 0:
                raw_text = result[0]["text"]
                processed_text = rich_transcription_postprocess(raw_text)
                
                # è§£æç»“æœ
                result_dict = self._parse_result(raw_text, processed_text)
                return result_dict
            else:
                return {"error": "æœªè¯†åˆ«åˆ°å†…å®¹"}
                
        except Exception as e:
            print(f"âŒ è¯†åˆ«å¤±è´¥: {str(e)}")
            return {"error": str(e)}
    
    def _parse_result(self, raw_text, processed_text):
        """
        è§£æè¯†åˆ«ç»“æœï¼Œæå–å„ç§ä¿¡æ¯
        """
        result = {
            "text": processed_text,
            "raw_text": raw_text,
            "language": "unknown",
            "emotion": "unknown", 
            "events": [],
            "itn_applied": False
        }
        
        # è§£æè¯­è¨€æ ‡ç­¾
        if "<|zh|>" in raw_text:
            result["language"] = "ä¸­æ–‡"
        elif "<|en|>" in raw_text:
            result["language"] = "è‹±è¯­"
        elif "<|yue|>" in raw_text:
            result["language"] = "ç²¤è¯­"
        elif "<|ja|>" in raw_text:
            result["language"] = "æ—¥è¯­"
        elif "<|ko|>" in raw_text:
            result["language"] = "éŸ©è¯­"
        
        # è§£ææƒ…æ„Ÿæ ‡ç­¾
        emotions = {
            "<|HAPPY|>": "å¼€å¿ƒ",
            "<|SAD|>": "æ‚²ä¼¤", 
            "<|ANGRY|>": "æ„¤æ€’",
            "<|NEUTRAL|>": "ä¸­æ€§",
            "<|FEARFUL|>": "ææƒ§",
            "<|DISGUSTED|>": "åŒæ¶",
            "<|SURPRISED|>": "æƒŠè®¶"
        }
        
        for tag, emotion in emotions.items():
            if tag in raw_text:
                result["emotion"] = emotion
                break
        
        # è§£æéŸ³é¢‘äº‹ä»¶
        events = {
            "<|BGM|>": "èƒŒæ™¯éŸ³ä¹",
            "<|Speech|>": "è¯­éŸ³",
            "<|Applause|>": "æŒå£°", 
            "<|Laughter|>": "ç¬‘å£°",
            "<|Cry|>": "å“­å£°",
            "<|Sneeze|>": "æ‰“å–·åš",
            "<|Cough|>": "å’³å—½"
        }
        
        for tag, event in events.items():
            if tag in raw_text:
                result["events"].append(event)
        
        # æ£€æŸ¥æ˜¯å¦åº”ç”¨äº†ITN
        if "<|withitn|>" in raw_text:
            result["itn_applied"] = True
        
        return result
    
    def batch_transcribe(self, audio_files, language="auto", use_itn=True):
        """
        æ‰¹é‡è½¬å½•å¤šä¸ªéŸ³é¢‘æ–‡ä»¶
        """
        results = []
        total = len(audio_files)
        
        print(f"ğŸ“ å¼€å§‹æ‰¹é‡å¤„ç† {total} ä¸ªéŸ³é¢‘æ–‡ä»¶...")
        
        for i, audio_path in enumerate(audio_files, 1):
            print(f"\n[{i}/{total}] å¤„ç†: {os.path.basename(audio_path)}")
            result = self.transcribe_file(audio_path, language, use_itn)
            result["file_path"] = audio_path
            results.append(result)
        
        print(f"\nâœ… æ‰¹é‡å¤„ç†å®Œæˆï¼å…±å¤„ç† {total} ä¸ªæ–‡ä»¶")
        return results

def main():
    """æ¼”ç¤ºåŸºæœ¬ç”¨æ³•"""
    print("ğŸ¯ SenseVoiceSmall åŸºç¡€æ¼”ç¤º")
    print("=" * 50)
    
    # è¯·ä¿®æ”¹ä¸ºæ‚¨çš„å®é™…æ¨¡å‹è·¯å¾„
    MODEL_PATH = None  # è®¾ç½®ä¸º None ä¼šè‡ªåŠ¨æœç´¢æœ¬åœ°æ¨¡å‹
    
    try:
        # åˆå§‹åŒ–æ¨¡å‹
        demo = SenseVoiceDemo(model_path=MODEL_PATH, device="auto")
        base_dir = os.path.dirname(os.path.abspath(__file__))

        # ç¤ºä¾‹éŸ³é¢‘è·¯å¾„ï¼ˆè¯·æ›¿æ¢ä¸ºæ‚¨çš„å®é™…éŸ³é¢‘æ–‡ä»¶ï¼‰
        audio_files = [
            os.path.join(base_dir, "models/SenseVoiceSmall/example/zh.mp3"),
            os.path.join(base_dir, "models/SenseVoiceSmall/example/en.mp3"),
        ]

        print(f"ğŸ“‚ ç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶: {', '.join(audio_files)}")
        
        # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        existing_files = [f for f in audio_files if os.path.exists(f)]
        
        if existing_files:
            # å•ä¸ªæ–‡ä»¶è½¬å½•
            print("\n1ï¸âƒ£ å•ä¸ªæ–‡ä»¶è½¬å½•æ¼”ç¤º")
            result = demo.transcribe_file(existing_files[0], language="auto")
            print(f"ğŸ“„ è¯†åˆ«ç»“æœ: {result}")
            
            # æ‰¹é‡è½¬å½•
            if len(existing_files) > 1:
                print("\n2ï¸âƒ£ æ‰¹é‡è½¬å½•æ¼”ç¤º")
                batch_results = demo.batch_transcribe(existing_files[:2])
                for result in batch_results:
                    print(f"ğŸ“ {os.path.basename(result['file_path'])}: {result['text']}")
        else:
            print("âš ï¸  æœªæ‰¾åˆ°ç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶")
            print("ğŸ’¡ è¯·å°†éŸ³é¢‘æ–‡ä»¶è·¯å¾„ä¿®æ”¹ä¸ºæ‚¨çš„å®é™…æ–‡ä»¶è·¯å¾„")
            print("æ”¯æŒæ ¼å¼: wav, mp3, flac, m4a ç­‰")
            
            # æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹
            print("\nğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
            print("demo = SenseVoiceDemo()")
            print('result = demo.transcribe_file("your_audio.wav")')
            print("print(result['text'])")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main()
